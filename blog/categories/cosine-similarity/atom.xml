<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cosine similarity | My Blog]]></title>
  <link href="https://www.noppanit.com/blog/categories/cosine-similarity/atom.xml" rel="self"/>
  <link href="https://www.noppanit.com/"/>
  <updated>2017-02-20T13:32:04+07:00</updated>
  <id>https://www.noppanit.com/</id>
  <author>
    <name><![CDATA[Noppanit Charassinvichai]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Cosine Similarity for Dummies]]></title>
    <link href="https://www.noppanit.com/cosine-similarity-for-dummies/"/>
    <updated>2015-10-30T08:35:17+07:00</updated>
    <id>https://www.noppanit.com/cosine-similarity-for-dummies</id>
    <content type="html"><![CDATA[<p>Have you ever wonder how recommender system works? Or How Spotify or Amazon recommends what songs you might like or what product you might like to buy. I do. In this post, I’m going to try to explain how the recommendation algorithm works. First, let’s create a perfect scenario. I like to create an ideal example, it’s easier to understand.</p>

<p>Let’s say you have a very simple data of movies that users like collected from your site and you would like to match those people together based on their interests. How would you do that? One of the most popular methods is <a href="https://en.wikipedia.org/wiki/Cosine_similarity">Cosine Similarity</a>. When I first saw the name I was so confused; why Cosine? I remember when I was a kid I remembered my teacher told me about trigonometry so why does it have to do with that?</p>

<p>Here’s the sample data.</p>

<p>User 1 likes these movies</p>

<p><code>plain
['Superman', 'Walking Dead', 'CSI']
</code></p>

<p>User 2 likes these movies</p>

<p><code>plain
['Superman', 'Walking Dead', 'CSI']
</code></p>

<p>Even without any algorithm we can say that two users like the same movies. But we want the algorithm to tell us that the two users are very similar. Before we get into the mathematical formula world. We have to understand what a vector is?</p>

<h1 id="whats-a-vector">What’s a vector?</h1>
<p>In Pyhsics, a vector has two things; magnitude and direction which can be written as</p>

<p><img src="/wp-content/uploads/2015/11/vector.png" title="Vector" ></p>

<p>I’d like to explain what a vector is but this <a href="http://immersivemath.com/ila/ch02_vectors/ch02.html">site</a> explains a lot better.</p>

<p>However, in Computer Science, 1-dimentional array is called a <a href="http://www.cplusplus.com/reference/vector/vector/">vector</a>. But <code>list</code> in Python cannot perform vector operation so we have to use <code>numpy</code> or you have to build your own which I don’t recommend.</p>

<p>Now we know what a vector is but how does it relate to Cosine Similarity. In a nutshell, Cosine Similarity is <a href="http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/">a measure that calculates the cosine of the angle between them</a>.</p>

<h1 id="cosine-similarity">Cosine Similarity</h1>

<p><img src="/wp-content/uploads/2015/11/cosine_similarity.gif" title="Cosine Similarity" ></p>

<p>In order to find the angle between the two vectors, we need to find the dot product of the two vectors as the formula below.</p>

<p>\begin{align}
\text{cosine-similarity}(A,B) = \frac{\left&lt;A,B\right&gt;}{||A||\cdot||B||}
\end{align}</p>

<h1 id="show-me-the-code">Show me the code</h1>

<p>Ok. enough about explanation, show me the code.</p>

<p>``` python
import numpy as np</p>

<p>def cosin_sim(v, w):
    return np.dot(v, w) / np.math.sqrt(np.dot(v, v) * np.dot(w, w))</p>

<h1 id="if-movie-is-in-the-list-of-movies-and-0-is-not">1 if movie is in the list of movies and 0 is not.</h1>
<p>cosin_sim([1, 1, 1], [1, 1, 1])
# 1.0</p>

<p>```</p>

<p>In the perfect example, we can see that the two users have the same interests.</p>

]]></content>
  </entry>
  
</feed>
